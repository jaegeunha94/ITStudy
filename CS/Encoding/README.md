# 텍스트 파일

텍스트 파일이란, 글자들이 씌어 있는 파일이다.
사람이 눈으로 직접 내용을 읽을 수 있다.

텍스트 파일은 아스키 파일이라고도 한다.  
대부분의 텍스트 파일이 아스키 코드 (ASCII Code)로 글자들을 나타내기 때문이다.
Plain Text File 이라고도 한다.  
"암호화되지 않은 평범한 텍스트"라는 뜻이다.

텍스트 파일의 대표적인 확장자는 ".txt" 이다.  
또한 .c .cpp .pl .bat .java .html .xml .css 등의 각종 프로그래밍 소스들과 웹문서도 텍스트 파일이다.

텍스트 모드에서는 "\n"은 "\r\n"으로 변경되어 저장된다. 분명 "\n"로 저장했는데 "\r\n"으로 바뀌었다.  
실제로 파일의 바이트 수를 살펴봐도 자신이 저장한 문자열에 "\r"이 추가되어 1byte가 추가됨을 알 수 있다.  
그렇다면 결국 개행 하나에 1byte가 추가되는 셈이다.

\r은 0x0D 로 저장되고 (1byte) 아스키 코드 13, \n은 0x0A 로 저장된다.(1byte)  
아스키 코드 10, 그리고 \r\n은 0x0D0x0A 형태가 될 것이다.



## 텍스트 파일의 장점

* 단순히 텍스트 편집기 만으로 리소스 파일을 생성, 수정 할 수 있다.
* 쉽게 파일의 내용을 살펴볼 수 있어서 디버깅이 쉽다.


# 바이너리 파일

이진 파일은, 바이너리 파일 Binary File 이라고도 한다.

"0"과 "1"이라는, 2진수 데이터만으로 이루어진 파일이다.  
(사실 텍스트 파일 역시 "0"과 "1"이라는, 2진수로 이루어져 있는 것은 마찬가지다.) 

사람이 직접 읽을 수는 없다.

.exe .dll 등의 프로그램 파일과, .zip .rar 등의 압축파일,  
.mp3 .mpg .jpg .gif 등의 멀티미디어 파일은 이진파일이다.


## 바이너리 파일의 장점

* 데이터를 처리하고 전송하는데 일반적으로 비용이 적게 든다.
* 보통 텍스트에 비해서 파싱이 쉬워서 데이터 처리 속도가 빠르다.
* 필요한 데이터 공간도 더 작은 경우가 많다.

## 텍스트 파일과 바이너리 파일의 차이

텍스트 파일도 바이너리 파일의 일종이다. 

바이너리 파일 중 문장을 읽기 편한 문자 코드만 사용해서 만들어진 파일이 텍스트 파일이다.

예상대로 바이너리 파일이 더 빠르게 처리 할 수 있을것 같다. 이유는 텍스트 파일의 경우 숫자  
하나가 8bit 의 아스키 코드로 이루어져 있어서 정수형 데이터 하나가 몇 bit 로 이루어 졌는지 탐색하는 비용이 크다.

하지만 바이너리 파일의 경우 정수형 데이터 하나는 4bit 으로 고정되어 있어서  
offset 값을 옮겨가면서 합을 구하면 더 빠르게 처리가 된다.

텍스트 파일은 개행 코드 전까지 모두 읽어 들일 수 있도록 NULL 코드가 없어야 한다.

이에 비해 바이너리 파일은 NULL 코드든, 개행 코드(0x0d), 0x01, 0x02, 등등 모든 코드를 자유롭게 저장할 수 있다.


# 문자 인코딩 (Character Encoding)
* 문자를 코드로 표현하는 방식
  * ex) 유니코드라는 문자 집합 을 표현하는 문자열 인코딩은 UTF-8, UTF-16, UTF-32 등이 있다.

사용자가 입력한 문자나 기호들을 컴퓨터가 이용할 수 있는 신호로 만드는 것.

컴퓨터는 모든 정보를 0과 1인 바이너리, 즉 숫자로 저장한다.

그러나 우리는 문서작업, 코딩, 메시지 등 컴퓨터에서 문자를 사용하여 입력하고 저장하며 처리하고 있다.

우리가 메모장에 한글로 문자열을 입력하여 저장하게 되면 컴퓨터가 한글을 어떻게 이해할 수 있을까?

입력된 한글을 컴퓨터가 이해할 수 있는 신호로 변환하는 과정이 일어났기 때문이다.

여기서 컴퓨터가 이해할 수 있는 신호란 앞서 말한 바이너리 데이터를 의미한다.

역으로, 디코딩이란 0과 1로 구성된 바이너리 데이터를 다시 문자로 복구하는 것이다.



# 문자 셋 (Character Set) = 코드표
* 사용할 수 있는 문자들의 집합
  * ex) 유니코드, ISO-8859, ASCII 등

바이너리 데이터로 변환하는 인코딩과 다시 문자로 변환하는 디코딩은 미리 정해진 규칙에 의해서 수행된다.

이렇게 미리 정해진 규칙을 문자 셋이라고 하며, 초기 표준 문자열 셋은 ASCII, EBCDIC ... 이었다.

그러나 인터넷이 전세계적으로 보급되며 표현해야 할 문자가 증가하면서 문자 셋들을 표준화 할 필요성이 대두되었다.

이후 등장하게 된 것이 유니코드이다. 


# 문자 인코딩과 문자 셋 차이
> 문자 인코딩과 문자 셋은 약간 다른 개념이다.  
> 문자 인코딩 : 문자를 컴퓨터가 이해할 수 있는 신호로 만드는 것   
> 문자 셋 : 인코딩과 디코딩을 위해 미리 정해진 규칙    

문자 인코딩이란, 컴퓨터가 이해할 수 있는 바이너리로 어떤 방법을 사용해도 상관없는 방법론  
문자 셋이란, 문자를 숫자로 매핑해주는 표이다.



예를 들어, base64 인코딩은 문자열을 아스키코드로 인코딩한 후 

다시 base64 코드표를 통해 인코딩을 수행한다.

이미 컴퓨터가 이해할 수 있는 아스키 코드로 인코딩된 문자열을 

새로운 base64 코드표로 인코딩한다는 것이다.


위의 예시와 같이 인코딩이란 바이너리를 생성하기 위한 과정이라고 볼 수 있다.

또한 아스키 인코딩과 같이 문자 셋과 문자 인코딩이 동일한 경우도 있기 때문에

인코딩이 문자 셋을 포함하고 있다고 생각할 수 있다.




# 조합형 방식

* 초성, 중성, 종성으로 구분하여 문자를 작성(총 3바이트의 문자로 인식)
* UTF-8은 조합형으로 거의 모든 한글을 표현 가능하다.



# 완성형 방식

* 하나의 문자를 하나의 완성되어있는 글자로 인식하는 방식
* 문자표를 토대로 문자를 인식
* 확장성이 떨어짐
* EUC-KR 방식은 완성형으로 조합형으로 표현 할 수 있는 모든 한글을 표현하지 못함
* CP949 방식은 완성형이지만 조합형으로 쓸 수 있는 거의 모든 한글을 포함



# 아스키 코드(ASCII)
* 처음으로 표준을 정립한 문자열 인코딩 방식으로 아직도 많이 사용된다.
* 사용할 수 있는 문자의 종류에는 대/소문자, 공백 및 특수 문자들이 있다.
* 문자를 표현할 때는 0 ~ 127까지 총 128개의 숫자를 사용한다.
* 아스키 코드는 영어를 제외한 다른 언어를 표현할 수 없다.
* 그래서 각 나라에서 아스키코드 대신 독자적인 문자 집합과 인코딩 방식을 만들었다.



## 아스키 코드(ASCII)는 왜 128개만 사용하는 걸까?

아스키코드는 1바이트를 사용한다.

그렇기 때문에 2^8 = 256개를 사용할 수 있지만

2^7 = 128개만 사용한다.

그 이유는 나머지 1bit를 통신 에러 검출을 위해 사용하기 때문이다.



## Parity Bit
7개의 비트 중    
1의 개수가 홀수면 1     
1의 개수가 짝수면 0으로 하는    
Parity Bit를 붙여 전송 도중 변질된 것을 검출해낸다.


매우 단순하고 간단하므로

어느 시스템에서도 적용 가능하다는 장점이 있다.

하지만 2바이트 이상의 코드를 표현할 수 없기 때문에

국제표준의 위상은 유니코드에게 넘어갔다.



## 아스키 코드와 유니코드와 호환성
UTF-8의 경우 ASCII 영역은 그대로 1바이트를 사용하기 때문에 호환이 된다.

그러므로 UTF-8으로 인코딩된 문서에서 ASCII 영역에 해당하는 문자만 적혀 있고

Byte Order Mark(BOM)까지 없다면 그냥 ASCII 문서와 다를 게 없다.

하지만 UTF-16은 2바이트에서 시작하기 때문에 호환이 되지 않는다.

이 때문에 UTF-16에서 ASCII 문자를 나타낼 때는 앞에 0x00이 붙는다.


ex) A라는 글자를 표현하려면 ASCII 혹은 UTF-8에서는 0x41이라고만 표현하면 되지만

UTF-16에서는 0x0041로 표현해야 한다.

이를 무시하고 1바이트로만 표현하면 앞뒤의 바이트가 묶여 다른 문자로 인식된다.



# iso-8859-1
ASCII 확장 이며 단일 바이트 고정 길이 인코딩이다


# ANSI 코드
아스키코드를 이용해 다른 언어를 표현하기에는 7비트로는 부족했다.  

그래서 8비트로 확장한 아스키 코드가 나왔다.  

사람들은 이 코드를 ANSI 코드라고 부르기 시작했다.

7비트에서 8비트로 확장되었으니 사람들이 활용할 수 있는 문자는 몇 개가 더 늘어났을까?  

1비트 늘어났으니 2개 더 늘어났다고 생각하면 안된다.  이렇게 되었으니 128개나 더 쓸 수 있게 되었다  
이때, 1바이트만으로 표현되는 경우를 SBCS(Single Byte Character Set)이라고도 한다.  
반대의 경우는 MBCS(Multi-Byte Character Set)이라고 한다.  

그러나 비유럽 국가 특히 한국, 중국, 일본과 같은 문자가 많은 국가에서는 여전히 제한적이다.  
(※ 우리나라의 경우 KSC5601 표준이라는 고유한 인코딩 방법으로 문자를 표현했다) 


그래서 유니코드(Unicode)라는 전 세계 언어의 문자를 정의하기 위한 국제 표준 코드가 등장하게 되었다.

ANSI의 앞 7bit는 ASCII와 동일하고 뒤에 1bit를 이용하여 다른 언어의 문자를 표현한다.

그런데 새로 추가 된 128개 문자로는 모든 언어의 문자를 표현할 수 없다.

그래서 생긴 개념이 Code Page이다. 각 언어별로 Code 값을 주고 Code마다 

다른 문자열 표를 의미하도록 약속을 했다.


쉽게 생각하면 아래와 같이 설명할 수 있다.

ANSI = ASCII(7bit) + CodePage(1bit)

이러한 원리를 고려하면 다음과 같이 정리할 수 있다.

영어만 사용하거나 ASCII를 사용할 경우 세계 어디에서나 사용에 문제가 없다.

영어 외 다른 언어를 사용할 경우 ANSI는 Code Page를 동일하게 맞춰야 한다.

Code Page가 다를 경우 의도와 다른 결과가 나올 수 있다.



# EUC-KR
한국에서는 EUC-KR 문자 집합을 만들었다.

한국어 문자 집합으로 문자 하나를 표현하기 위해 2바이트를 사용한다.

단 아스키코드 문자를 표현할 때는 1바이트를 사용하기 때문에 아스키코드와 호환이 된다.

EUC-KR에는 한글뿐만 아니라 숫자, 특수 기호, 영문, 한문, 일어가 존재한다.



# CP949
EUC-KR은 완성형 방식이고, 2바이트로 한글을 표현할 수 있게 만든 방식

아스키 값은 그대로 1바이트로 표현

CP949도 같은 2바이트를 사용

EUC-KR에서 표현할 수 없는 한글이 있어 마이크로소프트에서 CP949 사용 시작

CP949는 EUC-KR보다 많은 한글 표현 가능하며 윈도우에서 주로 쓰이는 인코딩 기법



# 유니코드

유니코드는 모든 문자에 Index를 지정하는 것이다.    
그 이상도 아니고, 그 이하도 아니다.

이 Index를 Code Point 혹은 Code Unit이라고 부르는데 일반적으로 Index라고 생각해도 무방하다.  

문자열을 숫자로 표현하기 위하여 문자 하나와 숫자 하나를 각각 매핑(=연결)한 것이 바로 유니코드이다.

예를 들어 A는 U+0041에 매핑되어 있고 ‘가’는 U+AC00에 매핑되어 있다.

유니코드를 인코딩하는 방법에는 UTF-8, UTF-16 등등 여러 방법이 존재한다.


## 한글 표현 가능 관계

ECU-KR  -> UTF-8 -> CP949(가능)

ECU-KR <- UTF-8 <- CP949(불가능)

확장 완성형인 CP949의 경우에는 유니코드(UTF-8)에서 표현할 수 있는 모든 문자를 표현 가능하다.

웹에서의 관계는 위처럼 표현 가능한 것이 아님

UTF-8이면 UTF-8, EUC-KR이면 EUC-KR끼리 밖에 제대로 표현 못함


# UTF
UTF는 몇 bit 단위로 사용해서 Index를 표현할 것인가를 뜻한다.

UTF-8은 8bit씩 Index를 표현

UTF-16은 16bit씩 Index를 표현

UTF-32는 32bit씩 Index를 표현한다는 뜻을 갖고 있다.

U+라는 접두어가 붙어있으면 유니코드

아스키코드 – 0x41 = A  /  유니코드 – U+0041 = A


# UTF-8
UTF-8은 Universal Coded Character Set + Transformation Format – 8-bit의 약자이다.  

UTF-8은 유니코드를 위한 가변 길이 문자 인코딩 방식 중 하나이다.  

UTF-8의 코드 단위는 8bit입니다.  

UTF-8 인코딩은 유니코드 한 문자를 나타내기 위해 1byte ~ 4byte까지를 사용한다.  

UTF-8은 인터넷에 교환되는 대부분의 파일에 사용된다.  영문 byte 수 : 1byte 한글 byte 수 : 3byte


# UTF-16
윈도우즈 메모장notepad에서 텍스트 파일 저장 시, 유니코드, 유니코드(big endian)이 바로 UTF-16에 해당한다.

UTF-16은 유니코드 문자 인코딩 방식의 하나이다.  

주로 사용되는 기본 다국어 평면(BMP, Basic multilingual plane)에 속하는 문자들은   
그대로 16bit값으로 인코딩이 되고 그 이상의 문자는 특별히 정해진 방식으로 32bit로 인코딩이 된다.  

UTF-16의 코드 단위는 16bit이다.  

UTF-16 인코딩은 유니코드 한 문자를 나타내기 위해 2byte ~ 4byte까지를 사용한다.  

UTF-16은 윈도우 응용프로그램, 자바스크립트 등의 작동시 사용된다.  영문 byte 수 : 2byte 한글 byte 수 : 2byte


## UTF-8 vs UTF-16

UTF-8과 UTF-16의 기본 차이는 문자 하나를 표현할 때 사용할 최소 byte 크기이다.

UTF-8로 문자를 표현할 때 1 ~ 4byte가 필요하다. 하지만 UTF-16은 2 ~ 4byte가 필요하다.

1byte: 영어

두 Encoding 방식의 큰 차이는 최소 8bit가 필요하냐 16bit가 필요하냐에 따라 다른 것이다.

최적의 상황(저장, 통신 용량을 아껴야할 때)이 필요하다면 어떤 CodePoint를 주로 사용하냐에 따라  
UTF-8 또는 UTF-16을 선택하는 기준이 달라질 것이다.


## UTF-16 LE (MS OS, Office용 유니코드)
컴퓨터에서 그냥 "유니코드"라고 부를 때에는 이 UTF-16 LE 를 가리키는 경우가 많다.

MS윈도우2000이나 윈도우XP에서 내부적으로 사용되는 유니코드이다.

그렇다고 해서 마이크로소프트(MS)가 개발했다는 뜻은 아니고, 표준 유니코드 중의 하나이다.

문자 1개를 16비트로 표현하는데, 앞의 8비트와 뒤의 8비트의 순서가 거꾸로 되어 있다.

인텔CPU가 Little-Endian 이기에, 유니코드도 앞뒤 바이트 순서를 바꾸면 이론적으로 더 처리 속도가 빨라진다.



## UTF-16 BE (Mac, JAVA용 유니코드)

BE는 Big-Endian 의 약자이다.

이것은 맥(Mac)이나 자바(Java)에서 사용되는 16비트 유니코드인데,  
앞뒤 바이트 순서가 거꾸로 바뀌지 않고 그대로 있는 것이다.

UTF-16 BE 는 윈도우에서는 거의 사용되지 않는다.



# BOM이란

BOM이란 문서 맨 앞에 눈에 보이지 않는 특정 바이트(byte)를 넣은 다음 이것을 해석해서  
정확히 어떤 인코딩 방식이 사용되었는지 알아내는 방법을 나타낸다.

자세하게 유니코드가 little-endian 인지 big-endian 인지 아니면 UTF-8 인지 쉽게 알 수 있도록,  
유니코드 파일이 시작되는 첫부분에 보이지 않게, 2~3바이트의 문자열을 추가하는데 이것을 BOM이라고 한다.

BOM은 텍스트 에디터 화면에서는 보이지 않고,  
헥사 에디터(Hex Editor)*로 열었을 때만 보인다.

UTF-16 이상 인코딩일 때, 문서의 맨 처음 BOM을 파악하여 Big Endian인지  
Little Endian인지 구분하지만 UTF-8의 경우는 BOM이 하나로 고정이다.

그래서 이 BOM은 바이트 순서와(Byte Order) 상관없기 때문에 UTF-8 Signature라고 불리기도 한다. 
즉, 해당 문서가 UTF-8로 인코딩되었다는 사실을 알리는 사인(signature)이다.



## BOM 문제점

UTF-8에는 BOM이 없는 것이 보통인데(UTF-8은 BOM이 고정이라 인코딩 방식을 자동으로 알 수 있음),  
일부 윈도우즈 프로그램(메모장 같은)은 UTF-8 파일을 생성할 때 자동으로 BOM을 집어넣는다.

윈도우즈 환경에서는 눈에 띄지 않는 경우가 많지만 리눅스(LINUX)나 유닉스(UNIX) 환경에서는 많은 문제를 일으키는 원인이 된다. 

BOM이 추가된 데이터의 경우, 글자 앞에 빈칸이 생기면 그 차이점을 알 수 있지만 대개 눈으론 보이지 않는다.

데이터베이스에서 BOM이 추가된 데이터와 그렇지 않은 데이터를 비교할 경우 눈으로는 동일한 데이터지만 비교를 할 땐 같지 않다는 데이터로 나온다. 

그 이유는 문자열 앞에 BOM이 붙어있기 때문이다.

울트라에디트라는 프로그램을 울트라에디트의 헥사 모드(Ctrl+H)로 UTF-8 파일을 보면,  
16비트 유니코드처럼 보이고 BOM이 있든 없든 항상 FF FE 라는 엉뚱한 BOM이 나타난다.

이것은 울트라에디터가 유니코드를 편집할 때,  
내부적으로 '16비트 little-endian 유니코드 (UTF-16LE)'로 변환하여 편집하기 때문이다.

진짜 헥사 에디터로 보아야만 UTF-8의 BOM인 EF BB BF 가 제대로 보이게 된다.  
물론 BOM이 없는 UTF-8이라면 BOM이 없는 것으로 나온다.

가장 좋은 방법으로는 메모장 같은 프로그램보단 BOM설정이 가능한 프로그램을 사용하는 것이다.

하지만 모든 파일을 BOM설정이 가능한 프로그램을 사용할 수 없기 때문에 BOM파일을 받은 다음,  
코드로 해당 파일을 UTF-8로 인코딩 처리하는 부분도 생각해야 한다.


# 참조
[studyforus tistory](https://studyforus.tistory.com/167)

[goodgid github io](https://goodgid.github.io/ASCII-Code/)
